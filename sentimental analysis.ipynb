{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Performing  sentiment analysis on following dataset.Using logistic regression. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.datasets import load_files\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pickle\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews=load_files(\"tokens/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=reviews.data,reviews.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"X.pickle\",\"wb\") as f:\n",
    "    pickle.dump(X,f)\n",
    "\n",
    "with open(\"y.pickle\",\"wb\") as f:\n",
    "    pickle.dump(y,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"X.pickle\",\"rb\") as f:\n",
    "    Xp=pickle.load(f)\n",
    "    \n",
    "with open(\"y.pickle\",\"rb\") as f:\n",
    "    yp=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "for i in range(0,len(X)):\n",
    "    reviews=re.sub(r\"\\W\",\" \",str(X[i]))#removing ! like\n",
    "    reviews=reviews.lower()\n",
    "    reviews=re.sub(r\"\\s+[a-z]\\s+\",\" \",reviews)#removing single character a i etc also going to use stopwords later\n",
    "    reviews=re.sub(r\"^[a-z]\\s+\",\" \",reviews)#single char in starting \n",
    "    reviews=re.sub(r\"\\s+\",\" \",reviews)#extra spaces removing\n",
    "    corpus.append(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' directed by david lynch screenplay by john roach and mary sweeney starring richard farnsworth sissy spacek james cada running time 106 minutes rated pg mfcb reviewed on april 24th 2000 the straight story tells tale that would seem too far fetched to be believed if it hadn actually happened based on true events from the summer of 1994 director david lynch newest film is an unusual choice of project for the man behind sometimes baffling fare like twin peaks and lost highway but the straight story is pleasant and engrossing and is also rare motion picture that dares not only to feature largely elderly cast but also to treat them with considerable respect alvin straight richard farnsworth is 73 years old world war ii veteran who has seen better days his hips are giving out on him and his emphysema is getting worse he lives with his daughter rose sissy spacek who is mildly retarded but bright enough in her own way one stormy night alvin learns from relative that his brother lyle has suffered stroke alvin and lyle were once as close as brothers could be but they had falling out ten years earlier and haven spoken since desperately aware of both lyle mortality and his own alvin decides he has to make the journey from his home in laurens iowa to lyle place in mount zion wisconsin neither alvin nor rose have driver license and alvin is too proud to ask anyone else for help so alvin decides to hitch trailer up to his battered old riding lawnmower and set out for wisconsin travelling no more than five or ten miles day his lawnmower soon breaks down but alvin is not swayed he trades it in and uses the last of his money to buy 1966 john deere mower then starts the journey all over again alvin slow voyage from iowa to wisconsin provides the framework around which the bulk of the movie is built as is often the case in these sorts of films the destination here is not nearly as important as what happens en route indeed the ending of the straight story is beautifully underplayed scene real lesson in minimality that demonstrates lynch trust in his audience the straight story is the odyssey writ small with alvin trundling from episode to episode like wrinkly old odysseus none of these little stories are particularly fascinating but put together they form touching mosaic it is through these chance encounters that alvin character is most fully illuminated and moreover that we are afforded glimpse of the effect his passage has on others some of these meetings are funny alvin witnesses collision between car and deer and learns that the driver barbara robertson has killed more than dozen of the creatures along that stretch of highway in the past six weeks the problem is that she has to drive that route back and forth every day to get to work beyond quitting her job or moving she simply has no other choice and love deer she wails other meetings are more serious alvin is nearly killed when he loses his brakes going down steep hill shaken up and out of money until his next welfare cheque comes in he is taken in by danny and darla riordan james cada and sally wingert the riordans friend verlyn heller wiley harker is wwii veteran like alvin and one day at the local tavern the two share stories of the horrors of war this is beautifully acted sequence and again lynch shows faith in his viewers by leaving it static and quiet so that the audience can conjure in their own minds the scenes that alvin and verlyn relate as alvin farnsworth does very good job in an academy award nominated performance he gives the character considerable depth his delivery in sequences like the aforementioned tavern scene are tinged with lifetime of emotions the only real drawback to the role and the same could be said of the straight story as whole is that alvin comes across as just little too sweet too coy although the very fact that he chose to endure the six week journey is indicative of alvin character found it difficult to believe that he could really be so cherubic and indeed reports suggest that the real alvin straight who died in 1996 was not quite as lovable as the movie implies don think viewer sympathy would have been lost by giving alvin bit more of an edge and think it would have made him generally better rounded none of the other actors have substantial screen time but there is not poor performance in the entire movie lynch is successful in coaxing just the right note out of all his cast be it dramatic or comedic like stanley kubrick in 2001 space odyssey lynch successfully conveys the lethargic pace of alvin trip there are long periods consisting of nothing but shots of iowa farmland for instance and more than once the camera pans up from alvin to the blue summer sky in traditional passage of time shot only to pan down again to show him just few yards further along this may induce boredom in some viewers but for the most part felt lynch handled such scenes judiciously they go on long enough to achieve their intended effect but not so long that began glancing at my wristwatch the fact that these sequences are accompanied by gorgeous fiddle music composed by lynch frequent collaborator angelo badalamenti doesn hurt either quiet unassuming gentle endearing the straight story is delightful film here is testimony not just to the principle that truth is stranger than fiction and not just to one man character and determination but also to the innumerable little stories that are out there just down the road waiting to be discovered copyright xa9 2000 shannon patrick sullivan archived at the popcorn gallery href http www physics mun ca sps movies thestraightstory html http www physics mun ca sps movies thestraightstory html _______________________________________________________________________ shannon patrick sullivan we are all in the gutter but some of us href mailto shannon morgan ucs mun ca shannon morgan ucs mun ca are looking at the stars oscar wilde ___________________________ __________________________________________ popcorn gallery movie reviews www physics mun ca sps movies html doctor who brief history of time travel drwho html n '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer=CountVectorizer(max_features=2000,min_df=3,max_df=0.6,stop_words=stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=vectorizer.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X#bagofwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transform=TfidfTransformer()\n",
    "X=transform.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.09082542],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)#random state is 0 so we get the same results\n",
    "#text_train,text_test,sent_train,sent_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1120, 2000)\n",
      "(1120,)\n",
      "(280, 2000)\n",
      "(280,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression y/(y-1)=a+bx+cx2..n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier=LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,y_train)#model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[117,  20],\n",
       "       [ 30, 113]], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm#117 WERE -ve and 113 were +ve and model find it right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm[0][0]+cm[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.5"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "230/4  #57.5 acc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "117+20+30+113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle storing model\n",
    "with open (\"classifier\",\"wb\") as f:\n",
    "    pickle .dump(classifier,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks  a lot more improvment is required in training to reach 85% atleast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
